---
title: "Oblig3 - TMA4300"
author: "Martine Middelthon"
date: "30 3 2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Problem A

Our data consists of the non-Gaussian time series of length $T=100$ plotted below.

```{r}
# Load data and functions
helpR = source("probAhelp.R")
dataR = source("probAdata.R")
plot(1:100, data3A$x, xlab = "t", ylab = "x")
```

We consider the AR(2) model

$$
  x_t = \beta_1 x_{t-1} + \beta_2 x_{t-2} + e_t,
$$

where $e_t$ are independent and identically distributed random variables with zero mean and constant variance. We find the two estimators $\hat{\boldsymbol\beta}_{LS}$ and $\hat{\boldsymbol\beta}_{LA}$ by respectively minimizing $Q_{LS}$ and $Q_{LA}$, where

$$
  Q_{LS}(\mathbf{x}) = \sum_{t=3}^T (x_t - \beta_1 x_{t-1} - \beta_2 x_{t-2})^2 \\
  Q_{LA}(\mathbf{x}) = \sum_{t=3}^T |x_t - \beta_1 x_{t-1} - \beta_2 x_{t-2}| .
$$


## 1.

We use the residual sampling bootstrap method to estimate the variance and bias of the estimators.

```{r}
set.seed(1)                   # For reproducibility
x = data3A$x                  # Time series data
betas = ARp.beta.est(x, 2)    # Estimated LS and LA coefficients


# Function to produce B bootstrap samples of the LS and LA coefficients
# Using the method of bootstrapping residuals
bootstrap.betas = function(x, betas, B=1500) {
  T = length(x)
  betaLS = betas[[1]]
  betaLA = betas[[2]]
  # Calculate observed (centralized) residuals
  resids.est.LS = ARp.resid(x, betaLS)
  resids.est.LA = ARp.resid(x, betaLA)
  # Matrices to store the bootstrap samples
  bootstrap.betaLS = matrix(0, nrow = length(betaLS), ncol = B)
  bootstrap.betaLA = matrix(0, nrow = length(betaLA), ncol = B)
  
  # Create bootstrap samples
  for (i in (1:B)) {
    # Pick random consecutive sequence x0 from the data
    random.index = sample(1:99, 1)
    x0 = c(x[random.index], x[random.index+1])
    x0 = rev(x0) # Revert the sequence
    # Create a sample of the residuals
    resample.residLS = sample(resids.est.LS, size = T, replace = TRUE)    
    resample.residLA = sample(resids.est.LA, size = T, replace = TRUE)
    # Calculate new sequence of data
    x.bootstrap.LS = ARp.filter(x0, betaLS, resample.residLS)[3:(T+2)]
    x.bootstrap.LA = ARp.filter(x0, betaLA, resample.residLA)[3:(T+2)]
    # Estimate coefficients based on the sequence
    betas1 = ARp.beta.est(x.bootstrap.LS, 2)
    betas2 = ARp.beta.est(x.bootstrap.LA, 2)
    # Store the bootstrap coefficients
    bootstrap.betaLS[,i] = betas1[[1]]
    bootstrap.betaLA[,i] = betas2[[2]]
  }
  
  return(rbind(bootstrap.betaLS, bootstrap.betaLA))
}

betas.boot = bootstrap.betas(x, betas, 1500)  # Bootstrapped LS and LA coefficients

betaLS.var = c(var(betas.boot[1,]), var(betas.boot[2,]))    # ( var(beta_{LS,1}), var(beta_{LS,2}) )
betaLA.var = c(var(betas.boot[3,]), var(betas.boot[4,]))    # ( var(beta_{LA,1}), var(beta_{LA,2}) )

cat("Variance of LS estimator:", betaLS.var)
cat("\nVariance of LA estimator:", betaLA.var)

betaLS.mean = c(mean(betas.boot[1,]), mean(betas.boot[2,]))   # ( mean(beta_{LS,1}), mean(beta_{LS,2}) )
betaLA.mean = c(mean(betas.boot[3,]), mean(betas.boot[4,]))   # ( mean(beta_{LA,1}), mean(beta_{LA,2}) )

betaLS.bias = betaLS.mean - betas[[1]]    # ( bias(beta_{LS,1}), bias(beta_{LS,2}) )
betaLA.bias = betaLA.mean - betas[[2]]    # ( bias(beta_{LA,1}), bias(beta_{LA,2}) )

cat("\n\nBias of LS estimator:", betaLS.bias)
cat("\nBias of LA estimator:", betaLA.bias)
```

### OPTIMAL?

## 2.

```{r}
library(MASS)

predictionInterval = function(x, betas, B=1500) {
  T = length(x)
  betaLS = betas[[1]]
  betaLA = betas[[2]]
  # Calculate observed residuals
  resids.est.LS = ARp.resid(x, betaLS)
  resids.est.LA = ARp.resid(x, betaLA)
  
  x101.LS = rep(0, B)
  x101.LA = rep(0, B)
  
  # Create bootstrap samples
  for (i in (1:B)) {
    # Pick random consecutive sequence x0 from the data
    random.index = sample(1:99, 1)
    x0 = c(x[random.index], x[random.index+1])
    x0 = rev(x0) # Revert the sequence
    # Create a sample of the residuals
    resample.residLS = sample(resids.est.LS, size = T, replace = TRUE)
    resample.residLA = sample(resids.est.LA, size = T, replace = TRUE)
    # Calculate new sequence of data
    x.bootstrap.LS = ARp.filter(x0, betaLS, resample.residLS)[3:(T+2)]    # Exclude initial sequence x0
    x.bootstrap.LA = ARp.filter(x0, betaLA, resample.residLA)[3:(T+2)]    # Exclude initial sequence x0
    # Estimate coefficients based on the sequence
    betasLS = ARp.beta.est(x.bootstrap.LS, 2)[[1]]
    betasLA = ARp.beta.est(x.bootstrap.LA, 2)[[2]]
    # Corresponding residuals
    boot.e101.LS = ARp.resid(x.bootstrap.LS, betasLS)
    boot.e101.LA = ARp.resid(x.bootstrap.LA, betasLA)
    # Pick random residual
    random = sample(1:length(boot.e101.LS),1)
    e101.LS = boot.e101.LS[random]
    e101.LA = boot.e101.LA[random]
    # Calculate x101 value
    x101.LS[i] = betasLS[1] * x[T] + betasLS[2] * x[T-1] + e101.LS
    x101.LA[i] = betasLA[1] * x[T] + betasLA[2] * x[T-1] + e101.LA
  }
  
  #truehist(x101.LS)
  #truehist(x101.LA)
  
  # Estimate quantiles
  quantilesLS = quantile(x101.LS, c(0.025, 0.975))
  quantilesLA = quantile(x101.LA, c(0.025, 0.975))
  
  return(rbind(quantilesLS, quantilesLA))
}

result = predictionInterval(x, betas, 1500)
result

```

We obtain the 95\% prediction intervals $(7.04,23.28)$ and $(7.68,20.80)$ for $x_{101}$ based on the LS and LA estimators, respectively. We observe that the latter interval is narrower.


